{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"NIunuZbBYqC5"},"source":["# Assignment # 11  \n","Park Juyeon, Department of Statistics and Data Science, 2022311137"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"5OTlWDXvYqDG"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import warnings\n","from numpy.linalg import inv, det\n","from statsmodels.stats import multivariate as mv\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n","from sklearn.metrics import confusion_matrix\n","\n","pd.options.display.float_format = '{:.5f}'.format\n","np.set_printoptions(suppress=True)\n","warnings.filterwarnings(action='ignore')\n","plt.rcParams['figure.facecolor'] = 'white'"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["----"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Q1. \n","### Write a Python code to calculate the linear discriminant function for several classes. Your code should be able to predict the Y class based on the input $x_o$ values."]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Linear discriminant function\n","def myLDA(X, y, prior, x0):\n","    \"\"\" Multivariate LDA \"\"\"\n","    # 1. Dividing groups\n","    n, p = X.shape\n","    classes, n_groups = np.unique(y, return_counts=True)\n","    g = len(classes)  # number of groups\n","\n","    # 1. Sample mean and sample covariance\n","    X_bar = np.zeros((g, p))\n","    S = []\n","    for i, name in enumerate(classes):\n","        X_bar[i, :] = X[y == name].mean()\n","        S.append(X[y == name].cov())\n","\n","    # 2. Pooled estimate of Sigma\n","    S_pooled = np.zeros((p, p))\n","    for i, n_group in enumerate(n_groups):\n","        S_pooled += (n_group - 1) * S[i] / (n - g)\n","\n","    # 3. d_i calculation\n","    ## Coefficient\n","    coef = [X_bar[i] @ inv(S_pooled) for i in range(g)]\n","    ## Constant\n","    const = [X_bar[i] @ inv(S_pooled) @ X_bar[i] * (-1/2)  \\\n","             + np.log(prior[i]) for i in range(g)]\n","    ## LDF\n","    d = [coef[i] @ x0 + const[i] for i in range(g)]\n","\n","    # 4. classification\n","    pred_idx = np.argmax(d)\n","    y_pred = classes[pred_idx]\n","    \n","    return y_pred, [d, coef, const]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["----"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Q2.\n","### Write a Python code to calculate the quadratic discriminant function for several classes. Your code should be able to predict the Y class based on the input $x_0$ values."]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# Linear discriminant function\n","def myQDA(X, y, prior, x0):\n","    \"\"\" Multivariate QDA \"\"\"\n","    # 1. Dividing groups\n","    n, p = X.shape\n","    classes, n_groups = np.unique(y, return_counts=True)\n","    g = len(classes)  # number of groups\n","\n","    # 1. Sample mean and sample covariance\n","    X_bar = np.zeros((g, p))\n","    S = []\n","    for i, name in enumerate(classes):\n","        X_bar[i, :] = X[y == name].mean()\n","        S.append(X[y == name].cov())\n","\n","    # Pooled estimate of Sigma\n","    d = [(-1/2) * (np.log(det(S[i])) + (x0-X_bar[i]) @ inv(S[i]) @ (x0-X_bar[i])) \\\n","         + np.log(prior[i]) for i in range(g)]\n","\n","    # 4. classification\n","    pred_idx = np.argmax(d)\n","    y_pred = classes[pred_idx]\n","    \n","    return y_pred, d"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["----"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Q3.\n","### Write a Python code to perform the ‘leave-one-out’ method to calculate the accuracy of the LDA & QDA model you wrote in #1 and #2."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def prediction(X, y, eval_type, prior, error_type):\n","    y_pred = np.zeros(len(X))\n","    for i in range(len(X)):\n","        # 1. Define target dataset\n","        if error_type == 'APER':\n","            new_X = X.copy()  # Use whole dataset to train and test\n","            new_y = y.copy()\n","        if error_type == 'LOO':\n","            new_X = X.drop(i, axis=0)  # leave ith observation to test set\n","            new_y = y.drop(i, axis=0)\n","        x0 = X.iloc[i, :]\n","        \n","        # 2. LDA\n","        y_pred_i, _ = eval_type(new_X, new_y, prior, x0)\n","        y_pred[i] = y_pred_i\n","    \n","    return y_pred\n","\n","# Accuracy\n","def calculate_accuracy(y, y_pred):\n","    accuracy = sum(y == y_pred) / len(y)\n","\n","    return accuracy"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["----"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Q4. \n","### Using Fisher’s Iris data, answer the following questions.\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sepal length</th>\n","      <th>Sepal width</th>\n","      <th>Petal length</th>\n","      <th>Petal width</th>\n","      <th>Class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5.10000</td>\n","      <td>3.50000</td>\n","      <td>1.40000</td>\n","      <td>0.20000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4.90000</td>\n","      <td>3.00000</td>\n","      <td>1.40000</td>\n","      <td>0.20000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4.70000</td>\n","      <td>3.20000</td>\n","      <td>1.30000</td>\n","      <td>0.20000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4.60000</td>\n","      <td>3.10000</td>\n","      <td>1.50000</td>\n","      <td>0.20000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5.00000</td>\n","      <td>3.60000</td>\n","      <td>1.40000</td>\n","      <td>0.20000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>145</th>\n","      <td>6.70000</td>\n","      <td>3.00000</td>\n","      <td>5.20000</td>\n","      <td>2.30000</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>146</th>\n","      <td>6.30000</td>\n","      <td>2.50000</td>\n","      <td>5.00000</td>\n","      <td>1.90000</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>147</th>\n","      <td>6.50000</td>\n","      <td>3.00000</td>\n","      <td>5.20000</td>\n","      <td>2.00000</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>148</th>\n","      <td>6.20000</td>\n","      <td>3.40000</td>\n","      <td>5.40000</td>\n","      <td>2.30000</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>149</th>\n","      <td>5.90000</td>\n","      <td>3.00000</td>\n","      <td>5.10000</td>\n","      <td>1.80000</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>150 rows × 5 columns</p>\n","</div>"],"text/plain":["     Sepal length  Sepal width  Petal length  Petal width  Class\n","0         5.10000      3.50000       1.40000      0.20000      1\n","1         4.90000      3.00000       1.40000      0.20000      1\n","2         4.70000      3.20000       1.30000      0.20000      1\n","3         4.60000      3.10000       1.50000      0.20000      1\n","4         5.00000      3.60000       1.40000      0.20000      1\n","..            ...          ...           ...          ...    ...\n","145       6.70000      3.00000       5.20000      2.30000      3\n","146       6.30000      2.50000       5.00000      1.90000      3\n","147       6.50000      3.00000       5.20000      2.00000      3\n","148       6.20000      3.40000       5.40000      2.30000      3\n","149       5.90000      3.00000       5.10000      1.80000      3\n","\n","[150 rows x 5 columns]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["iris = pd.read_csv('iris.dat', delim_whitespace = True, header = None)\n","Class_name = ['setosa', 'versicolor', 'virginica']\n","iris.columns = ['Sepal length', 'Sepal width', 'Petal length', 'Petal width', 'Class']  # [\"setosa\", 'versicolor', 'virginica']\n","iris"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["X = iris.iloc[:, :-1]\n","y = iris.iloc[:, -1]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["----"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## a. Is the assumption of a common covariance matrix reasonable in this case? (Use Python’s statsmodels.stats.multivariate’ module for this question)."]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Chi-Square Test stat: 140.94305, Pr > ChiSq: 0.00000\n","Reject H0\n"]}],"source":["## 등분산 검정(homogeneity of variance test) \n","# Covariance matrix for each group\n","classes, n_groups = np.unique(y, return_counts=True)\n","for i, name in enumerate(classes):\n","    globals()['cov' + str(i+1)] = X[y == name].cov()\n","\n","# Testing\n","test = mv.test_cov_oneway([cov1, cov2, cov3], n_groups)\n","print(f'Chi-Square Test stat: {test.statistic_chi2 :.5f}, Pr > ChiSq: {test.pvalue_chi2 :.5f}')\n","print('Reject H0')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["From homogenity of variance test, We can conclude that the groups do NOT satisfy homoscedastic assumption. (Reject H0)  \n","Therefore we should conduct QDA, not LDA."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["----"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## b. Assuming that the populations are multivariate normal, calculate the quadratic discriminant scores with equal prior and equal misclassification cost. Classify the new observation $x_0 = [5.0, 3.5, 1.75, 0.21]^T$ into one of population $\\pi_1, \\pi_2, \\pi_3$. (Use your code in #2 above)."]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The QDA scores are\n","   setosa  versicolor  virginica\n","0 3.49098   -47.30137  -74.70869 \n","\n","The the prediction is\n"]},{"data":{"text/plain":["'setosa'"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["prior = [1/3, 1/3, 1/3]\n","x0 = [5.0, 3.5, 1.75, 0.21]\n","\n","y_pred, score = myQDA(X, y, prior, x0)\n","score = pd.DataFrame(np.array(score).reshape(1, -1), columns=Class_name)\n","\n","print(f'The QDA scores are')\n","print(score, '\\n')\n","print(f'The the prediction is')\n","Class_name[y_pred - 1]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["The quadratic discriminant scores are [3.49, -47.30, -74.70] for setosa, versicolor and virginica, respectively. Therefore, the new observation x0 can be classified to setosa."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["----"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## c. Assuming equal covariance matrices and multivariate normal populations, calculate the linear discriminant function using your code in #1 above and compare its coefficient with those of Python’s ‘sklearn.discriminant_analysis’ module."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### LDA with code in #1"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The coefficients and constant of my LDA is \n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th>setosa</th>\n","      <th>versicolor</th>\n","      <th>virginica</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Const</th>\n","      <td>-86.30847</td>\n","      <td>-72.85261</td>\n","      <td>-104.36832</td>\n","    </tr>\n","    <tr>\n","      <th>Sepal length</th>\n","      <td>23.54417</td>\n","      <td>15.69821</td>\n","      <td>12.44585</td>\n","    </tr>\n","    <tr>\n","      <th>Sepal width</th>\n","      <td>23.58787</td>\n","      <td>7.07251</td>\n","      <td>3.68528</td>\n","    </tr>\n","    <tr>\n","      <th>Petal length</th>\n","      <td>-16.43064</td>\n","      <td>5.21145</td>\n","      <td>12.76654</td>\n","    </tr>\n","    <tr>\n","      <th>Petal width</th>\n","      <td>-17.39841</td>\n","      <td>6.43423</td>\n","      <td>21.07911</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                setosa versicolor  virginica\n","Const        -86.30847  -72.85261 -104.36832\n","Sepal length  23.54417   15.69821   12.44585\n","Sepal width   23.58787    7.07251    3.68528\n","Petal length -16.43064    5.21145   12.76654\n","Petal width  -17.39841    6.43423   21.07911"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["prior = [1/3, 1/3, 1/3]\n","x0 = [5.0, 3.5, 1.75, 0.21]\n","\n","y_pred, result  = myLDA(X, y, prior, x0)\n","score, coef, const = result\n","\n","coef = pd.DataFrame(coef,\n","                    index=[Class_name], \n","                    columns=iris.columns[:-1]).T\n","const = pd.DataFrame(np.array(const).reshape(1, -1),\n","                     index=['Const'], \n","                     columns=[Class_name])\n","LDA_info = pd.concat((const, coef), axis=0)\n","\n","print('The coefficients and constant of my LDA is ')\n","LDA_info"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### LDA with sklearn.discriminant_analysis"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Fit the LDA in sklearn.discriminant_analysis"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearDiscriminantAnalysis(priors=[0.3333333333333333, 0.3333333333333333,\n","                                   0.3333333333333333])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearDiscriminantAnalysis</label><div class=\"sk-toggleable__content\"><pre>LinearDiscriminantAnalysis(priors=[0.3333333333333333, 0.3333333333333333,\n","                                   0.3333333333333333])</pre></div></div></div></div></div>"],"text/plain":["LinearDiscriminantAnalysis(priors=[0.3333333333333333, 0.3333333333333333,\n","                                   0.3333333333333333])"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["lda = LDA(priors=prior)\n","lda.fit(X, y)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Get coefficients and constant"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","    </tr>\n","    <tr>\n","      <th>Variable</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Constant</th>\n","      <td>-15.47784</td>\n","      <td>-2.02197</td>\n","      <td>-33.53769</td>\n","    </tr>\n","    <tr>\n","      <th>Sepal length</th>\n","      <td>6.31476</td>\n","      <td>-1.53120</td>\n","      <td>-4.78356</td>\n","    </tr>\n","    <tr>\n","      <th>Sepal width</th>\n","      <td>12.13932</td>\n","      <td>-4.37604</td>\n","      <td>-7.76327</td>\n","    </tr>\n","    <tr>\n","      <th>Petal length</th>\n","      <td>-16.94642</td>\n","      <td>4.69567</td>\n","      <td>12.25076</td>\n","    </tr>\n","    <tr>\n","      <th>Petal width</th>\n","      <td>-20.77005</td>\n","      <td>3.06259</td>\n","      <td>17.70747</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     1        2         3\n","Variable                                 \n","Constant     -15.47784 -2.02197 -33.53769\n","Sepal length   6.31476 -1.53120  -4.78356\n","Sepal width   12.13932 -4.37604  -7.76327\n","Petal length -16.94642  4.69567  12.25076\n","Petal width  -20.77005  3.06259  17.70747"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["LDA_module = pd.DataFrame(np.append(lda.intercept_, lda.coef_.T).reshape(5,3),\n","                          index = ['Constant', 'Sepal length', 'Sepal width', 'Petal length', 'Petal width'],\n","                          columns = np.sort(y.unique()))\n","LDA_module.index.names = ['Variable']\n","LDA_module"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Confusion matrix"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>setosa</th>\n","      <th>versicolor</th>\n","      <th>virginica</th>\n","      <th>Total</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>setosa</th>\n","      <td>50</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>50</td>\n","    </tr>\n","    <tr>\n","      <th>versicolor</th>\n","      <td>0</td>\n","      <td>48</td>\n","      <td>2</td>\n","      <td>50</td>\n","    </tr>\n","    <tr>\n","      <th>virginica</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>49</td>\n","      <td>50</td>\n","    </tr>\n","    <tr>\n","      <th>Total</th>\n","      <td>50</td>\n","      <td>49</td>\n","      <td>51</td>\n","      <td>150</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            setosa  versicolor  virginica  Total\n","setosa          50           0          0     50\n","versicolor       0          48          2     50\n","virginica        0           1         49     50\n","Total           50          49         51    150"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["# Confusion matrix\n","\n","y_pred = lda.predict(X)\n","C1 = pd.DataFrame(confusion_matrix(y, y_pred))\n","C1.index = pd.Series(C1.index).map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})\n","C1.columns = pd.Series(C1.columns).map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})\n","C1['Total'] = C1.sum(axis=1)\n","C1.loc['Total'] = C1.sum(axis=0)\n","\n","C1"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Comparing the result of two methods, the coefficients and the constant are different."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["----"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## d. Calculate and compare the APER and the leave-one-out error rates for linear discriminant analysis (LDA) and quadratic discriminant analysis (QDA) using your code in #1, 2, 3. (Assume equal prior and equal misclassification cost)."]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy of LDA with APER is 0.98\n","Accuracy of LDA with LOO is 0.98\n","Accuracy of QDA with APER is 0.98\n","Accuracy of QDA with LOO is 0.9733333333333334\n"]}],"source":["y_pred = prediction(X, y, myLDA, prior, 'APER')\n","accuracy = calculate_accuracy(y, y_pred)\n","print(f'Accuracy of LDA with APER is {accuracy}')\n","\n","y_pred = prediction(X, y, myLDA, prior, 'LOO')\n","accuracy = calculate_accuracy(y, y_pred)\n","print(f'Accuracy of LDA with LOO is {accuracy}')\n","\n","y_pred = prediction(X, y, myQDA, prior, 'APER')\n","accuracy = calculate_accuracy(y, y_pred)\n","print(f'Accuracy of QDA with APER is {accuracy}')\n","\n","y_pred = prediction(X, y, myQDA, prior, 'LOO')\n","accuracy = calculate_accuracy(y, y_pred)\n","print(f'Accuracy of QDA with LOO is {accuracy}')"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"9e2073447a22768059a1d3cd58b75b52a5aca334e22b493fd97f709dbfa448be"}}},"nbformat":4,"nbformat_minor":0}
